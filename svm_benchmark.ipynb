{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 279 Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "{'description': 'Collection of ~8.4k decisions issued by the U.S. Supreme Court between November 1946 and June 2016.', 'data_dir': '/usr/local/lib/python3.5/dist-packages/textacy/data/supreme_court', 'name': 'supreme_court', 'site_url': 'http://caselaw.findlaw.com/court/us-supreme-court'}\n",
      "Found 8419 documents.\n",
      "Found 279 labels.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from textacy.datasets.supreme_court import SupremeCourt\n",
    "\n",
    "print('Processing text dataset')\n",
    "\n",
    "sc = SupremeCourt()\n",
    "print(sc.info)\n",
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "\n",
    "issue_codes = list(sc.issue_codes.keys())\n",
    "issue_codes.append('-1')\n",
    "issue_codes.sort()\n",
    "\n",
    "labels_index = dict(zip(issue_codes, np.arange(len(issue_codes))))\n",
    "\n",
    "for i,record in enumerate(sc.records(limit=-1)):\n",
    "    if record['issue'] == None: # some cases have None as an issue\n",
    "        labels.append(labels_index['-1'])\n",
    "    else:\n",
    "        labels.append(labels_index[record['issue']])\n",
    "    texts.append(record['text'])\n",
    "\n",
    "print('Found %s documents.' % len(texts))\n",
    "print('Found %s labels.' % len(labels_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29334916864608074\n",
      "0.30474934036939316\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf-svm', SVC(random_state=42)),\n",
    "])\n",
    "_ = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "print(np.mean(predicted_svm == y_test))\n",
    "\n",
    "\n",
    "predicted_svm = text_clf_svm.predict(X_val)\n",
    "print(np.mean(predicted_svm == y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.00      0.00      0.00         0\n",
      "          2       0.00      0.00      0.00         8\n",
      "          3       0.17      0.27      0.21        11\n",
      "          4       1.00      1.00      1.00         1\n",
      "          5       0.00      0.00      0.00         2\n",
      "          6       0.00      0.00      0.00         2\n",
      "          7       0.00      0.00      0.00         1\n",
      "          8       0.00      0.00      0.00         0\n",
      "          9       0.00      0.00      0.00         0\n",
      "         10       0.50      0.50      0.50         4\n",
      "         11       0.00      0.00      0.00         2\n",
      "         12       0.00      0.00      0.00         1\n",
      "         13       0.00      0.00      0.00         3\n",
      "         14       0.00      0.00      0.00         2\n",
      "         15       0.28      0.79      0.41        24\n",
      "         16       0.75      0.75      0.75         4\n",
      "         17       0.00      0.00      0.00         2\n",
      "         18       0.24      0.82      0.37        17\n",
      "         19       0.00      0.00      0.00        11\n",
      "         20       0.00      0.00      0.00         0\n",
      "         21       1.00      0.33      0.50         6\n",
      "         22       0.22      0.25      0.24         8\n",
      "         23       0.00      0.00      0.00         4\n",
      "         24       0.00      0.00      0.00         2\n",
      "         25       0.50      0.83      0.62         6\n",
      "         26       0.70      0.58      0.64        12\n",
      "         27       0.00      0.00      0.00         2\n",
      "         28       0.00      0.00      0.00         2\n",
      "         29       0.00      0.00      0.00         1\n",
      "         30       1.00      0.55      0.71        11\n",
      "         31       0.00      0.00      0.00         1\n",
      "         32       0.00      0.00      0.00         2\n",
      "         33       0.00      0.00      0.00         1\n",
      "         34       0.00      0.00      0.00         2\n",
      "         35       0.00      0.00      0.00         3\n",
      "         36       0.00      0.00      0.00         2\n",
      "         37       0.00      0.00      0.00         0\n",
      "         38       0.00      0.00      0.00         2\n",
      "         39       0.00      0.00      0.00         1\n",
      "         40       1.00      0.17      0.29         6\n",
      "         41       0.00      0.00      0.00         1\n",
      "         42       0.00      0.00      0.00         0\n",
      "         43       0.00      0.00      0.00         1\n",
      "         44       0.00      0.00      0.00         0\n",
      "         45       0.00      0.00      0.00         0\n",
      "         46       0.00      0.00      0.00         2\n",
      "         47       0.00      0.00      0.00         1\n",
      "         48       0.00      0.00      0.00         3\n",
      "         49       0.00      0.00      0.00         0\n",
      "         50       0.43      0.43      0.43         7\n",
      "         51       0.00      0.00      0.00         0\n",
      "         52       0.00      0.00      0.00         0\n",
      "         53       0.00      0.00      0.00         1\n",
      "         54       0.00      0.00      0.00         0\n",
      "         55       0.00      0.00      0.00         1\n",
      "         56       0.00      0.00      0.00         3\n",
      "         57       1.00      0.67      0.80         3\n",
      "         58       0.00      0.00      0.00         1\n",
      "         59       0.00      0.00      0.00         0\n",
      "         60       0.00      0.00      0.00         0\n",
      "         61       0.00      0.00      0.00         0\n",
      "         62       0.00      0.00      0.00         7\n",
      "         63       0.00      0.00      0.00         0\n",
      "         64       0.00      0.00      0.00         0\n",
      "         65       0.00      0.00      0.00         0\n",
      "         66       0.00      0.00      0.00         0\n",
      "         67       0.00      0.00      0.00         0\n",
      "         68       0.00      0.00      0.00         0\n",
      "         69       0.33      0.14      0.20         7\n",
      "         70       0.00      0.00      0.00         4\n",
      "         71       0.00      0.00      0.00         4\n",
      "         72       1.00      1.00      1.00         1\n",
      "         73       0.00      0.00      0.00         0\n",
      "         74       0.00      0.00      0.00         3\n",
      "         75       0.00      0.00      0.00         1\n",
      "         76       0.00      0.00      0.00         1\n",
      "         77       0.00      0.00      0.00         0\n",
      "         78       0.34      0.80      0.48        20\n",
      "         79       0.00      0.00      0.00         4\n",
      "         80       0.00      0.00      0.00         1\n",
      "         81       0.00      0.00      0.00         0\n",
      "         82       0.00      0.00      0.00         0\n",
      "         83       0.00      0.00      0.00         1\n",
      "         84       0.00      0.00      0.00         0\n",
      "         85       0.00      0.00      0.00         0\n",
      "         86       0.00      0.00      0.00         0\n",
      "         87       0.00      0.00      0.00         0\n",
      "         88       0.00      0.00      0.00         0\n",
      "         89       0.00      0.00      0.00         0\n",
      "         90       0.00      0.00      0.00         0\n",
      "         91       0.00      0.00      0.00         0\n",
      "         92       0.00      0.00      0.00         0\n",
      "         93       0.00      0.00      0.00         2\n",
      "         94       1.00      1.00      1.00         3\n",
      "         95       0.00      0.00      0.00         2\n",
      "         96       1.00      0.20      0.33         5\n",
      "         97       0.50      0.09      0.15        11\n",
      "         98       0.75      0.75      0.75         4\n",
      "         99       0.00      0.00      0.00         4\n",
      "        100       0.00      0.00      0.00         0\n",
      "        101       0.00      0.00      0.00         2\n",
      "        102       1.00      0.38      0.55         8\n",
      "        103       0.00      0.00      0.00         1\n",
      "        104       0.62      0.50      0.56        10\n",
      "        105       0.00      0.00      0.00         2\n",
      "        106       0.00      0.00      0.00         2\n",
      "        107       1.00      0.40      0.57         5\n",
      "        108       0.00      0.00      0.00         4\n",
      "        109       0.67      0.67      0.67         6\n",
      "        110       0.00      0.00      0.00         0\n",
      "        111       0.00      0.00      0.00         1\n",
      "        112       1.00      0.25      0.40         4\n",
      "        113       1.00      1.00      1.00         1\n",
      "        114       0.00      0.00      0.00         4\n",
      "        115       0.00      0.00      0.00         0\n",
      "        116       0.00      0.00      0.00         2\n",
      "        117       0.00      0.00      0.00         5\n",
      "        118       1.00      0.25      0.40         4\n",
      "        119       0.00      0.00      0.00         1\n",
      "        120       0.00      0.00      0.00         1\n",
      "        121       0.00      0.00      0.00         1\n",
      "        122       0.00      0.00      0.00         0\n",
      "        123       0.00      0.00      0.00         0\n",
      "        124       0.00      0.00      0.00         1\n",
      "        125       0.00      0.00      0.00         1\n",
      "        126       0.00      0.00      0.00         2\n",
      "        127       0.00      0.00      0.00         0\n",
      "        128       0.00      0.00      0.00         3\n",
      "        129       0.00      0.00      0.00         3\n",
      "        130       0.00      0.00      0.00         3\n",
      "        131       0.00      0.00      0.00         0\n",
      "        132       0.00      0.00      0.00         1\n",
      "        133       0.31      0.42      0.36        12\n",
      "        134       0.00      0.00      0.00         0\n",
      "        135       0.09      0.85      0.17        13\n",
      "        136       0.00      0.00      0.00         0\n",
      "        137       0.00      0.00      0.00         5\n",
      "        138       0.00      0.00      0.00         1\n",
      "        139       0.00      0.00      0.00         2\n",
      "        140       0.00      0.00      0.00         3\n",
      "        141       0.00      0.00      0.00         1\n",
      "        142       0.00      0.00      0.00         0\n",
      "        143       0.00      0.00      0.00         0\n",
      "        144       0.00      0.00      0.00         0\n",
      "        145       0.00      0.00      0.00         0\n",
      "        146       0.00      0.00      0.00         2\n",
      "        147       0.00      0.00      0.00         1\n",
      "        148       0.00      0.00      0.00         0\n",
      "        149       0.00      0.00      0.00         6\n",
      "        150       0.00      0.00      0.00         6\n",
      "        151       0.00      0.00      0.00         2\n",
      "        152       1.00      0.40      0.57         5\n",
      "        153       1.00      0.11      0.20         9\n",
      "        154       0.00      0.00      0.00         0\n",
      "        155       1.00      0.14      0.25         7\n",
      "        156       0.00      0.00      0.00         4\n",
      "        157       0.00      0.00      0.00         3\n",
      "        158       1.00      0.50      0.67         4\n",
      "        159       0.00      0.00      0.00         2\n",
      "        160       0.00      0.00      0.00         2\n",
      "        161       0.67      0.36      0.47        11\n",
      "        162       0.00      0.00      0.00         2\n",
      "        163       0.00      0.00      0.00         6\n",
      "        164       0.00      0.00      0.00         0\n",
      "        165       1.00      1.00      1.00         1\n",
      "        166       1.00      0.82      0.90        11\n",
      "        167       0.00      0.00      0.00         0\n",
      "        168       0.00      0.00      0.00         0\n",
      "        169       0.00      0.00      0.00         0\n",
      "        170       0.50      0.20      0.29         5\n",
      "        171       0.00      0.00      0.00         1\n",
      "        172       0.00      0.00      0.00         1\n",
      "        173       0.00      0.00      0.00         3\n",
      "        174       0.00      0.00      0.00         0\n",
      "        175       1.00      0.60      0.75         5\n",
      "        176       0.00      0.00      0.00         2\n",
      "        177       0.00      0.00      0.00         1\n",
      "        178       0.00      0.00      0.00         1\n",
      "        179       0.00      0.00      0.00         3\n",
      "        180       0.00      0.00      0.00         1\n",
      "        181       0.00      0.00      0.00         0\n",
      "        182       0.00      0.00      0.00         2\n",
      "        183       0.00      0.00      0.00         2\n",
      "        184       0.00      0.00      0.00         1\n",
      "        185       0.00      0.00      0.00         2\n",
      "        186       0.00      0.00      0.00         0\n",
      "        187       0.00      0.00      0.00         0\n",
      "        188       0.00      0.00      0.00         0\n",
      "        189       0.00      0.00      0.00         3\n",
      "        190       0.00      0.00      0.00         0\n",
      "        191       0.35      0.58      0.44        19\n",
      "        192       0.00      0.00      0.00         4\n",
      "        193       0.86      0.60      0.71        10\n",
      "        194       0.10      0.29      0.15         7\n",
      "        195       0.40      0.50      0.44         8\n",
      "        196       0.44      0.44      0.44        18\n",
      "        197       0.56      0.38      0.45        13\n",
      "        198       0.00      0.00      0.00         1\n",
      "        199       0.67      0.67      0.67         3\n",
      "        200       0.46      0.55      0.50        11\n",
      "        201       0.00      0.00      0.00         0\n",
      "        202       0.00      0.00      0.00        10\n",
      "        203       0.50      0.17      0.25         6\n",
      "        204       0.33      0.67      0.44         3\n",
      "        205       0.00      0.00      0.00         2\n",
      "        206       0.00      0.00      0.00         0\n",
      "        207       0.00      0.00      0.00         1\n",
      "        208       0.00      0.00      0.00         5\n",
      "        209       1.00      0.50      0.67         2\n",
      "        210       0.00      0.00      0.00         1\n",
      "        211       0.00      0.00      0.00         4\n",
      "        212       0.00      0.00      0.00         1\n",
      "        213       0.00      0.00      0.00         7\n",
      "        214       0.00      0.00      0.00         1\n",
      "        215       0.00      0.00      0.00         4\n",
      "        216       0.00      0.00      0.00         0\n",
      "        217       0.00      0.00      0.00         0\n",
      "        218       0.00      0.00      0.00         1\n",
      "        219       0.00      0.00      0.00         0\n",
      "        220       0.00      0.00      0.00         0\n",
      "        221       0.00      0.00      0.00         2\n",
      "        222       0.00      0.00      0.00         0\n",
      "        223       0.00      0.00      0.00         0\n",
      "        224       0.00      0.00      0.00         0\n",
      "        225       0.00      0.00      0.00         0\n",
      "        226       0.00      0.00      0.00         1\n",
      "        227       0.00      0.00      0.00         0\n",
      "        228       0.00      0.00      0.00         1\n",
      "        229       0.00      0.00      0.00         1\n",
      "        230       0.00      0.00      0.00         1\n",
      "        231       0.00      0.00      0.00         0\n",
      "        232       0.00      0.00      0.00         0\n",
      "        233       0.00      0.00      0.00         0\n",
      "        234       0.00      0.00      0.00         0\n",
      "        235       0.00      0.00      0.00         2\n",
      "        236       0.00      0.00      0.00         0\n",
      "        237       0.83      0.50      0.62        10\n",
      "        238       0.18      0.76      0.29        17\n",
      "        239       0.00      0.00      0.00         5\n",
      "        240       0.00      0.00      0.00         2\n",
      "        241       0.14      0.73      0.23        15\n",
      "        242       0.00      0.00      0.00         1\n",
      "        243       0.00      0.00      0.00         0\n",
      "        244       0.00      0.00      0.00         3\n",
      "        245       0.00      0.00      0.00         1\n",
      "        246       0.00      0.00      0.00         0\n",
      "        247       0.00      0.00      0.00         1\n",
      "        248       0.00      0.00      0.00         0\n",
      "        249       0.00      0.00      0.00         0\n",
      "        250       0.00      0.00      0.00         2\n",
      "        251       0.00      0.00      0.00         2\n",
      "        252       0.00      0.00      0.00         0\n",
      "        253       0.00      0.00      0.00         0\n",
      "        254       0.00      0.00      0.00         3\n",
      "        255       0.00      0.00      0.00         0\n",
      "        256       0.00      0.00      0.00         1\n",
      "        257       0.00      0.00      0.00         0\n",
      "        258       0.00      0.00      0.00         5\n",
      "        259       0.00      0.00      0.00         3\n",
      "        260       0.00      0.00      0.00         2\n",
      "        261       0.00      0.00      0.00         0\n",
      "        262       0.00      0.00      0.00         2\n",
      "        263       0.00      0.00      0.00         2\n",
      "        264       1.00      0.14      0.25         7\n",
      "        265       0.00      0.00      0.00         3\n",
      "        266       0.00      0.00      0.00         0\n",
      "        267       0.00      0.00      0.00         0\n",
      "        268       0.00      0.00      0.00         2\n",
      "        269       0.00      0.00      0.00         0\n",
      "        270       0.00      0.00      0.00         0\n",
      "        271       0.00      0.00      0.00         0\n",
      "        272       0.00      0.00      0.00         1\n",
      "        273       0.00      0.00      0.00         1\n",
      "        274       0.00      0.00      0.00         1\n",
      "        275       0.00      0.00      0.00         0\n",
      "        276       0.00      0.00      0.00         1\n",
      "        277       0.00      0.00      0.00         1\n",
      "        278       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.32      0.30      0.26       758\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_val, predicted_svm, labels=np.arange(len(issue_codes)))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Collection of ~8.4k decisions issued by the U.S. Supreme Court between November 1946 and June 2016.', 'data_dir': '/usr/local/lib/python3.5/dist-packages/textacy/data/supreme_court', 'name': 'supreme_court', 'site_url': 'http://caselaw.findlaw.com/court/us-supreme-court'}\n",
      "Found 8419 texts.\n",
      "Found 15 labels.\n"
     ]
    }
   ],
   "source": [
    "sc = SupremeCourt()\n",
    "print(sc.info)\n",
    "\n",
    "texts = []  # list of text samples\n",
    "labels_index = {}  # dictionary mapping label name to numeric id\n",
    "labels = []  # list of label ids\n",
    "\n",
    "issue_codes = list(sc.issue_area_codes.keys())\n",
    "issue_codes.sort()\n",
    "issue_codes = [str(ic) for ic in issue_codes]\n",
    "\n",
    "labels_index = dict(zip(issue_codes, np.arange(len(issue_codes))))\n",
    "\n",
    "for i,record in enumerate(sc.records(limit=-1)):\n",
    "    if record['issue'] == None: # some cases have None as an issue\n",
    "        labels.append(labels_index['-1'])\n",
    "    else:\n",
    "        labels.append(labels_index[record['issue'][:-4]])\n",
    "    texts.append(record['text'])\n",
    "\n",
    "print('Found %s texts.' % len(texts))\n",
    "print('Found %s labels.' % len(labels_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6258907363420427\n",
      "0.6398416886543535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('clf-svm', SVC(random_state=42)),\n",
    "])\n",
    "_ = text_clf_svm.fit(X_train, y_train)\n",
    "predicted_svm = text_clf_svm.predict(X_test)\n",
    "print(np.mean(predicted_svm == y_test))\n",
    "\n",
    "\n",
    "predicted_svm = text_clf_svm.predict(X_val)\n",
    "print(np.mean(predicted_svm == y_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00         1\n",
      "          1       0.73      0.83      0.78       183\n",
      "          2       0.74      0.52      0.61       121\n",
      "          3       0.89      0.61      0.72        56\n",
      "          4       0.86      0.18      0.30        33\n",
      "          5       1.00      0.11      0.20         9\n",
      "          6       1.00      0.64      0.78        11\n",
      "          7       0.88      0.67      0.76        33\n",
      "          8       0.57      0.77      0.65       145\n",
      "          9       0.41      0.69      0.52       102\n",
      "         10       0.56      0.15      0.24        33\n",
      "         11       0.00      0.00      0.00         5\n",
      "         12       0.93      0.56      0.70        25\n",
      "         13       0.00      0.00      0.00         1\n",
      "         14       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       0.68      0.64      0.63       758\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_val, predicted_svm, labels=np.arange(len(issue_codes)))\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
